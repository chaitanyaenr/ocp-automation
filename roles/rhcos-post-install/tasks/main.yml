---
- name: Get cluster name
  shell: |
    {%raw%}oc get machineset -n openshift-machine-api -o=go-template='{{(index (index .items 0).metadata.labels "sigs.k8s.io/cluster-api-cluster")}}'{%endraw%}
  register: rhcos_cluster_name

- name: Get cluster ID
  shell: |
    {%raw%}oc get machineset -n openshift-machine-api -o=go-template='{{with (index .items 0)}}{{range .spec.template.spec.providerSpec.value.tags}}{{if eq .name "openshiftClusterID"}}{{.value}}{{end}}{{end}}{{end}}'{%endraw%}
  register: rhcos_cluster_id

- name: Get AMI ID
  shell: |
    {%raw%}oc get machineset -n openshift-machine-api -o=go-template='{{(index .items 0).spec.template.spec.providerSpec.value.ami.id}}'{%endraw%}
  register: rhcos_ami_id

- name: Get cluster region
  shell: |
    {%raw%}oc get machineset -n openshift-machine-api -o=go-template='{{(index .items 0).spec.template.spec.providerSpec.value.placement.region}}'{%endraw%}
  register: rhcos_region

- name: Get public subnet name
  shell: aws ec2 describe-subnets --filters "Name=tag:kubernetes.io/cluster/{{ OPENSHIFT_INSTALL_CLUSTER_NAME }},Values=owned" "Name=cidrBlock,Values=10.0.0.0/20" | grep "Name" | awk '{print $3}'
  register: rhcos_cluster_public_subnet

- name: Place machineset yamls on master
  template:
    src: "{{item.src}}"
    dest: "{{item.dest}}"
  with_items:
     - src: infra-node-machineset.yml.j2
       dest: /root/infra-node-machineset.yml
     - src: pbench-node-machineset.yml.j2
       dest: /root/pbench-node-machineset.yml

- name: Get current ready node count
  shell: oc get nodes | grep " Ready" -ic
  register: rhcos_current_node_count

- name: Create machinesets
  shell: |
    oc create -f infra-node-machineset.yml,pbench-node-machineset.yml

- name: Poll nodes to see if creating nodes finished
  shell: oc get nodes | grep " Ready" -ic
  register: current_node_count
  # + 3 (infra nodes) + 1 (pbench controller node)
  until: current_node_count.stdout|int == (rhcos_current_node_count.stdout|int + 3 + 1)
  delay: 1
  retries: "{{POLL_ATTEMPTS|int}}"

- name: Relabel the infra nodes
  shell: |
    oc label nodes --overwrite -l 'node-role.kubernetes.io/infra=' node-role.kubernetes.io/worker-

- name: Relabel the pbench controller node
  shell: |
    oc label nodes --overwrite -l 'node-role.kubernetes.io/pbench=' node-role.kubernetes.io/worker-

- name: Disable CVO to prevent squashed configuration changes to cluster operators
  shell: |
    oc scale --replicas 0 -n openshift-cluster-version deployments/cluster-version-operator

- name: Taint the pbench controller node
  shell: |
    oc adm taint node -l node-role.kubernetes.io/pbench= dedicated=pbench:NoSchedule

- name: Copy new cluster-monitoring-config
  copy:
    src: cluster-monitoring-config.yml
    dest: /root/cluster-monitoring-config.yml

- name: Replace the cluster-monitoring-config ConfigMap
  shell: |
    oc create -f cluster-monitoring-config.yml
  ignore_errors: yes

- name: Remove existing nodeSelector from monitoring
  shell: |
    oc patch deployment.apps/cluster-monitoring-operator -n openshift-monitoring --type json -p '[{"op": "remove", "path": "/spec/template/spec/nodeSelector"}]'

- name: Remove existing nodeSelector from ingress
  shell: |
    oc patch clusteringresses/default -n openshift-ingress-operator --type json -p '[{"op": "remove", "path": "/spec/nodePlacement/nodeSelector/matchLabels"}]'

- name: Apply new node-selector to infra workload components
  shell: |
    oc patch {{item.object}} {{item.type|default('',True)}} -n {{item.namespace}} -p {{item.patch}}
  with_items:
    # Monitoring (Relocate from worker nodes)
    - namespace: openshift-monitoring
      object: deployment.apps/cluster-monitoring-operator
      patch: |
        '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
     # Registry (Relocate from master nodes)  - Does not require CVO Disable
    - namespace: openshift-image-registry
      object: deployment.apps/cluster-image-registry-operator
      patch: |
        '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
    - namespace: openshift-image-registry
      object: deployment.apps/image-registry
      patch: |
        '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
    # Ingress/Router (Relocate from worker nodes) - Does not require CVO Disable
    - namespace: openshift-ingress-operator
      object: deployment.apps/ingress-operator
      patch: |
        '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
    - namespace: openshift-ingress-operator
      object: clusteringresses/default
      patch: |
        '{"spec": {"nodePlacement": {"nodeSelector": {"matchLabels": {"node-role.kubernetes.io/infra": ""}}}}}'
      type: "--type merge"
        # Logging (If it is installed)
        # - namespace: openshift-logging
        #   object: deployment.apps/cluster-logging-operator
        #   patch: |
        #     '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
        # - namespace: openshift-logging
        #   object: deployment.apps/elasticsearch-clientdatamaster-0-1
        #   patch: |
        #     '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
        # - namespace: openshift-logging
        #   object: deployment.apps/elasticsearch-operator
        #   patch: |
        #     '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
        # - namespace: openshift-logging
        #   object: deployment.apps/kibana
        #   patch: |
        #     '{"spec": {"template": {"spec": {"nodeSelector": {"node-role.kubernetes.io/infra": ""}}}}}'
